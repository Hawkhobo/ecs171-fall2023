{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this assignment, we will be exploring the car dataset and analyzing their fuel efficiency. <br >\n",
    "Specifically, we will do some exploratory analysis with visualizations, then we will build a model for Simple Linear Regression, a model for Polynomial Regression, and one model for Logistic Regression. <br >\n",
    "**The given dataset is already modified and cleaned**, but you can find [the original information here.](https://archive.ics.uci.edu/ml/datasets/auto+mpg).\n",
    "\n",
    "## Dataset Attribute Information\n",
    "\n",
    "1. **mpg**: Miles per gallon. This is one primary measurement for car fuel efficiency.\n",
    "2. **displacement** : The cylinder volumes in cubic inches.\n",
    "3. **horsepower** : Engine power.\n",
    "4. **weight** : In pounds.\n",
    "5. **acceleration** : The elapsed time in seconds to go from 0 to 60mph.\n",
    "6. **origin** : Region of origin.\n",
    "\n",
    "### Libraries that can be used: numpy, pandas, scikit-learn, seaborn, plotly, matplotlib\n",
    "Any libraries used in the discussion materials are also allowed.\n",
    "\n",
    "#### Other Notes\n",
    " - Don't worry about not being able to achieve high accuracy, it is neither the goal nor the grading standard of **this** assignment. <br >\n",
    " - If not specified, you are not required to do hyperparameter tuning, but feel free to do so if you'd like.\n",
    " - Discussion materials should be helpful for doing the assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mpg  displacement  horsepower  weight  acceleration  origin\n",
      "0    18.0         307.0       130.0  3504.0          12.0     USA\n",
      "1    15.0         350.0       165.0  3693.0          11.5     USA\n",
      "2    18.0         318.0       150.0  3436.0          11.0     USA\n",
      "3    16.0         304.0       150.0  3433.0          12.0     USA\n",
      "4    17.0         302.0       140.0  3449.0          10.5     USA\n",
      "..    ...           ...         ...     ...           ...     ...\n",
      "387  27.0         140.0        86.0  2790.0          15.6     USA\n",
      "388  44.0          97.0        52.0  2130.0          24.6  Europe\n",
      "389  32.0         135.0        84.0  2295.0          11.6     USA\n",
      "390  28.0         120.0        79.0  2625.0          18.6     USA\n",
      "391  31.0         119.0        82.0  2720.0          19.4     USA\n",
      "\n",
      "[392 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data_dist = pd.read_csv('auto-mpg.csv')\n",
    "print(data_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "## Exercise 1 - Exploratory Analysis (20 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1 - Correlation Matrix (10 points)\n",
    "Generate a Pearson [correlation matrix plot](https://heartbeat.fritz.ai/seaborn-heatmaps-13-ways-to-customize-correlation-matrix-visualizations-f1c49c816f07) in the form of a heatmap. See the link to have an idea about what this visualization should look like. <br >\n",
    "After generating the plot, answer the following question: <br >\n",
    "**If we are going to predict ``mpg`` in Simple Linear Regression(i.e., $y=ax+b$), which attribute are you most UNLIKELY to pick as the independent variable? Explain why.**\n",
    "\n",
    "Requirements & notes\n",
    " - When computing correlation, make sure to drop the column ``origin`` to avoid errors.\n",
    " - The computed correlation values should be shown on the plot.\n",
    " - Use a diverging color scale with the color range being \\[-1, 1\\] and center being 0 (if applicable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2 - Pairplot (10 points)\n",
    "Generate a pairplot(a.k.a. scatter plot matrix) of the given dataset. <br >\n",
    "After generating the plot, answer the following question: <br >\n",
    "**If we are using ``horsepower`` to predict ``mpg``, which method could lead to the best performance? (Linear Regression, Polynomial Regression, or Logistic Regression) Explain why.**\n",
    "\n",
    "Note that there is no requirement on the diagonals. You can leave empty or use other representations based on your preference. However, having ``origin``-based grouped data distributions on the diagonals effectively helps you answer some questions in the later exercises.   \n",
    "\n",
    "Requirements\n",
    " - The points should be colored based on the column ``origin``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Linear and Polynomial Regression (30 points in total)\n",
    "\n",
    "### Exercise 2.1 - Splitting Dataset (5 points)\n",
    "Split the data into training and testing set with the ratio of 80:20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 - Simple Linear Regression (10 points)\n",
    "Using one of the other attributes(excluding ``origin``) by your choice, please build a simple linear regression model that predicts ``mpg``. <br >\n",
    "\n",
    "Requirements\n",
    " - Report the testing MSE error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3 - Polynomial Regression (15 points)\n",
    "Build polynomial regression models that predict ``mpg`` with the same choice in 2.2. <br >\n",
    "Specifically, from degree=2 to degree=4, build one respectively. <br >\n",
    "Then, based on the reported errors from only these three degrees, **do you think there is a sign of overfitting? Provide your reasoning.**\n",
    "\n",
    "\n",
    "Requirements\n",
    " - Report the training MSE error for each of the three degrees.\n",
    " - Report the testing MSE error for each of the three degrees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Overfitting and Underfitting (25 points in total)\n",
    "The fitting dataset contains the actual train and test data spread for a model along with three rotations of the same. The dataset is provided in the Canvas file.\n",
    "\n",
    "### Exercise 3.1 - sse and variance\n",
    "Calculate the sse and variance for the three predictions based on the actual data.<br >\n",
    "Show the calculation for the above metrics.<br >\n",
    "Highlight the values you get for all three predictions and the actual data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.2 - Justification\n",
    "Based on the values calculated above classify the predictions into three categories base prediction, overfitting prediction, underfitting prediction. Also provide appropriate justifications for the classifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Outliers (25 points in total)\n",
    "Now we are going to perform outlier detection using the diabetes dataset. \n",
    "The dataset is provided in the Canvas file.\n",
    "\n",
    "### Exercise 4.1 - box plot\n",
    "Extract the 'BloodPressure' attribute from the diabetes dataset.<br >\n",
    "Create a box plot with the 'BloodPressure' attribute.<br >\n",
    "Highlight the outliers in the box plot with special colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2 - anomaly detection\n",
    "Extract features 'BMI' and 'Insulin' from the diabetes dataset.<br >\n",
    "Implement anomaly detection using the One-Class SVM algorithm.<br >\n",
    "Plot a scatter plot similar to Lecture 2 Slide 11, annotating the outlier data points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
